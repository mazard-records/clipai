{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4GhhH25OdYq"
      },
      "source": [
        "# Stable Diffusion Videos\n",
        "\n",
        "This notebook allows you to generate videos by interpolating the latent space of [Stable Diffusion](https://github.com/CompVis/stable-diffusion).\n",
        "\n",
        "You can either dream up different versions of the same prompt, or morph between different text prompts (with seeds set for each for reproducibility).\n",
        "\n",
        "If you like this notebook:\n",
        "- consider giving the [repo a star](https://github.com/nateraw/stable-diffusion-videos) ⭐️\n",
        "- consider following me on Github [@nateraw](https://github.com/nateraw) \n",
        "\n",
        "You can file any issues/feature requests [here](https://github.com/nateraw/stable-diffusion-videos/issues)\n",
        "\n",
        "Enjoy 🤗"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvdCBpWWOhW-"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xwfc0ej1L9A0"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install realesrgan stable_diffusion_videos[realesrgan]\n",
        "! git config --global credential.helper store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dR5iVGYbOky5"
      },
      "source": [
        "### Authenticate with Hugging Face Hub\n",
        "\n",
        "You have to be a registered user in 🤗 Hugging Face Hub, and you'll also need to use an access token for the code to work. For more information on access tokens, please refer to [this section of the documentation](https://huggingface.co/docs/hub/security-tokens).\n",
        "\n",
        "  > ⚠️ **Important**: You must also go to the [model repository](https://huggingface.co/CompVis/stable-diffusion-v1-4) and click \"Access Repository\" so you can download the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmejIGhFMTXG"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kidtsR3c2P9Z"
      },
      "outputs": [],
      "source": [
        "#@title Connect to Google Drive to Save Outputs\n",
        "\n",
        "#@markdown If you want to connect Google Drive, click the checkbox below and run this cell. You'll be prompted to authenticate.\n",
        "\n",
        "#@markdown If you just want to save your outputs in this Colab session, don't worry about this cell\n",
        "\n",
        "connect_google_drive = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Then, in the interface, use this path as the `output` in the Video tab to save your videos to Google Drive:\n",
        "\n",
        "#@markdown > /content/gdrive/MyDrive/stable_diffusion_videos\n",
        "\n",
        "\n",
        "if connect_google_drive:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLXULBMwSDnY"
      },
      "source": [
        "## Generate video clip for Ballet Dancer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup seeds and prompts"
      ],
      "metadata": {
        "id": "wNJIn5RZ51_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Seeds generator\n",
        "\n",
        "Generate random seeds only once to be then copied into the next setup script"
      ],
      "metadata": {
        "id": "C43-o6xq9A-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Number of seed to generate, adapt to your need\n",
        "N = 61\n",
        "\n",
        "print([random.randint(2000000000, 8000000000) for _ in range(N)])"
      ],
      "metadata": {
        "id": "jGknVea287VQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parameters"
      ],
      "metadata": {
        "id": "OS-BGLWr9S75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_path = '/content/Ballet Dancer - draft 3.mp3'\n",
        "# Audio duration in seconds\n",
        "# duration = 350\n",
        "duration = 70\n",
        "\n",
        "# Audio offset (every 5 seconds)\n",
        "offsets = list(range(0, duration, 5))\n",
        "\n",
        "# List of original seeds used for the first part of the song\n",
        "# NOTE: seeds must be fixed and not random to provide\n",
        "#       reproductibility\n",
        "seeds = [\n",
        "    6871596188, 7042399203, 4066412822, 7484131661, 3425344691, 3779981234,\n",
        "    7163318970, 7148941744, 3335470119, 6964904650, 5851479726, 7041406661,\n",
        "    2823231592,\n",
        "]\n",
        "\n",
        "fps = 30\n",
        "steps =  [(b-a) * fps for a, b in zip(offsets, offsets[1:])]\n",
        "\n",
        "\n",
        "# NOTE: on free GPU limit is 2, premium GPU limit is 10\n",
        "batch_size = 10\n",
        "\n",
        "# NOTE: Google Drive root relative path\n",
        "drive_folder = 'stable-diffusion'\n",
        "name = 'ballet-dancer'"
      ],
      "metadata": {
        "id": "ph43cLG64M44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prompts"
      ],
      "metadata": {
        "id": "yZ6Yjs2T9WE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE : 2 was supposed to be 'rhads' but mistake at first seeding\n",
        "artists = ['ivan aivazovsky', 'greg rutkowski', 'rutkowski']\n",
        "container = 'beautiful painting'\n",
        "cues = [\n",
        "    'digital art',\n",
        "    'hyper detailed, sharp focus, soft light',\n",
        "    'octane render',\n",
        "    'ray tracing',\n",
        "    'trending on artstation'\n",
        "]\n",
        "\n",
        "template = ''.join([\n",
        "    'A ',\n",
        "    container,\n",
        "    ' of {0} by ',\n",
        "    ' and '.join(artists),\n",
        "    ', in style of ',\n",
        "    '. '.join(cues)\n",
        "])\n",
        "\n",
        "# NOTE: Size must be (duration / time_per_prompt)\n",
        "prompts = [\n",
        "    template.format(prompt)\n",
        "    for prompt in [\n",
        "      # 0:00\n",
        "      'a ballet dancer girl in a city',\n",
        "      'a ballet dancer girl watching a skyscraper',\n",
        "      'a ballet dancer girl dancing with a skyscraper',\n",
        "      'a skyscraper transforming into a burger',\n",
        "      'a ballet dancer girl eating a burger in a city',\n",
        "      'a burger transforming into a man shadow',\n",
        "      'a ballet dancer girl watching a man shadow leaving',\n",
        "      'a ballet dancer girl crying in a city',\n",
        "      'a ballet dancer girl disappearing in dust',\n",
        "      'a ballet dancer girl wake up in a forest',\n",
        "      'a ballet dancer girl dancing in a forest',\n",
        "      'a ballet dancer girl dancing with a tree',\n",
        "      # 1:00\n",
        "    ]\n",
        "]\n",
        "\n",
        "print(prompts)"
      ],
      "metadata": {
        "id": "uRGSz5GE5AvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load model from HuggingFace\n",
        "\n",
        "This step will take a couple minutes the first time you run it."
      ],
      "metadata": {
        "id": "BHI3BE8u5yt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from stable_diffusion_videos import StableDiffusionWalkPipeline, Interface\n",
        "\n",
        "from diffusers.models import AutoencoderKL\n",
        "from diffusers.schedulers import LMSDiscreteScheduler\n",
        "\n",
        "pipeline = StableDiffusionWalkPipeline.from_pretrained(\n",
        "    'runwayml/stable-diffusion-v1-5',\n",
        "    vae=AutoencoderKL.from_pretrained(f\"stabilityai/sd-vae-ft-ema\"),\n",
        "    torch_dtype=torch.float16,\n",
        "    revision=\"fp16\",\n",
        "    safety_checker=None,\n",
        "    scheduler=LMSDiscreteScheduler(\n",
        "        beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\"\n",
        "    )\n",
        ").to(\"cuda\")"
      ],
      "metadata": {
        "id": "wmA0R0JW5kHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate video"
      ],
      "metadata": {
        "id": "sb0N4wOt7VQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = pipeline.walk(\n",
        "    prompts=prompts,\n",
        "    seeds=seeds,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=10,\n",
        "    margin=1.0,\n",
        "    smooth=0.2,\n",
        "    resume=True,\n",
        "    upsample=True,\n",
        "    num_interpolation_steps=steps,\n",
        "    height=512, width=512,\n",
        "    audio_filepath=audio_path,\n",
        "    audio_start_sec=offsets[0],\n",
        "    fps=fps,\n",
        "    batch_size=batch_size,\n",
        "    output_dir=f'/content/gdrive/MyDrive/{drive_folder}',\n",
        "    name=name,\n",
        ")\n",
        "print(f'video generated at {path}')"
      ],
      "metadata": {
        "id": "sf2Cq13A7Uao"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "dvdCBpWWOhW-",
        "dR5iVGYbOky5",
        "C43-o6xq9A-r",
        "OS-BGLWr9S75",
        "yZ6Yjs2T9WE3",
        "sb0N4wOt7VQL"
      ],
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "7d7b96a25c39fa7937ff3ab94e1dd8c63b93cb924b8f0093093c6266e25a78bc"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
